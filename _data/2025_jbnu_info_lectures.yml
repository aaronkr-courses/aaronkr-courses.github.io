- date: 9/1
  week: 1
  title: >
    <strong>Introduction</strong>
  supp:
  readings:
  hw:
  slides: "https://docs.google.com/presentation/d/1PCqHQq9XjynWK_brYQQDSH7mxZUhf4K93Pg9ivIhRc4/edit?usp=sharing"
  slides2:
  img: 2025/jbnu-info/1-intro.jpg
  logistics: >
    <a href="https://docs.google.com/presentation/d/1KJgk9eaXtaVf_SEy5XcxJ5Om4xsv6LDYUl729R_pays/edit?usp=sharing">
      Conference Presentation Info
    </a>

- date: 9/8
  week: 2
  title: >
    0. What is Information?<br>
    1. Introduction to Information Theory<br>
    2. Probability, Entropy, and Inference<br>
    3. More about Inference
  supp:
  readings:
  hw: "https://classroom.github.com/a/htg-Yrej"
  slides: "https://docs.google.com/presentation/d/1g_wN1T6o0O1kOCuF7DLiW4mSqraUFQTjZ8bwFMbdY3U/edit?usp=sharing"
  slides2:
  img: 2025/jbnu-info/2-info.jpg
  logistics:

- date: 9/15
  week: 3
  title: >
    <strong>I: Data Compression</strong><br>
    4. The Source Coding Theorem<br>
    5. Symbol Codes<br>
    6. Stream Codes<br>
    7. Codes for Integers
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 9/22
  week: 4
  title: >
    <strong>II: Noisy-Channel Coding</strong><br>
    8. Dependent Random Variables<br>
    9. Communication over a Noisy Channel<br>
    10. The Noisy-Channel Coding Theorem<br>
    11. Error-Correcting Codes and Real Channels
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 9/29
  week: 5
  title: >
    <strong>III: Further Topics in Information Theory</strong><br>
    12. Hash Codes: Codes for Efficient Information Retrieval<br>
    13. Binary Codes<br>
    14. Very Good Linear Codes Exist<br>
    15. Further Exercises on Information Theory
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 10/6
  week: 6
  title: >
    <span style="color: red"><strong>No Class</strong> Chuseok!~</span>

- date: 10/13
  week: 7
  title: >
    <strong>III: Further Topics in Information Theory</strong><br>
    16. Message Passing<br>
    17. Communication over Constrained Noiseless Channels<br>
    18. Crosswords and Codebreaking<br>
    19. Why? Information Acquisition and Evolution
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 10/20
  week: 8
  title: >
    <strong>Midterm Test</strong>
    <div style="display: none;">
      <br><a href="https://docs.google.com/presentation/d/10fbnjsPThjdAY70T_91tLPwxrTQ9JssKHU52dmVtvzs/edit?usp=sharing">스터디 가이드</a>
      <br><a href="https://forms.gle/wBXEg8Byt55so6VY7">중간퀴즈</a>
    </div>

- date: 10/27
  week: 9
  title: >
    <strong>IV: Probabilities and Inference</strong><br>
    20. A Example Inference Task: Clustering<br>
    21. Exact Inference by Complete Enumeration<br>
    22. Maximum Likelihood and Clustering<br>
    23. Useful Probability Distributions<br>
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 11/3
  week: 10
  title: >
    <strong>IV: Probabilities and Inference</strong><br>
    24. Exact Marginalization<br>
    25. Exact Marginalization in Trellises<br>
    26. Exact Marginalization in Graphs<br>
    27. Laplace's Method
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 11/10
  week: 11
  title: >
    <strong>IV: Probabilities and Inference</strong><br>
    28. Model Comparison and Occam's Razor<br>
    29. Monte Carlo Methods<br>
    30. Efficient Monte Carlo Methods<br>
    31. Ising Models<br>
    32. Exact Monte Carlo Sampling
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 11/17
  week: 12
  title: >
    <strong>IV: Probabilities and Inference</strong><br>
    33. Variational Methods<br>
    34. Independent Component Analysis and Latent Variable Modelling<br>
    35. Random Inference Topics<br>
    36. Decision Theory<br>
    37. Bayesian Inference and Sampling Theory
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 11/24
  week: 13
  title: >
    <strong>V: Neural Networks</strong><br>
    38. Introduction to Neural Networks<br>
    39. The Single Neuron as a Classifier<br>
    40. Capacity of a Single Neuron<br>
    41. Learning as Inference
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 12/1
  week: 14
  title: >
    <strong>V: Neural Networks</strong><br>
    42. Hopfield Networks<br>
    43. Boltzmann Machines<br>
    44. Supervised Learning in Multilayer Networks<br>
    45. Gaussian Processes<br>
    46. Deconvolution
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 12/8
  week: 15
  title: >
    <strong>VI: Sparse Graph Codes</strong><br>
    47. Low-Density Parity-Check Codes<br>
    48. Convolutional Codes and Turbo Codes<br>
    49. Repeat-Accumulate Codes<br>
    50. Digital Fountain Codes
  supp:
  readings:
  hw:
  slides:
  slides2:
  img:
  logistics:

- date: 12/15
  week: 16
  title: >
    <strong>Final Test</strong>
    <div style="display: none;">
      <br><a href="https://docs.google.com/presentation/d/10fbnjsPThjdAY70T_91tLPwxrTQ9JssKHU52dmVtvzs/edit?usp=sharing">스터디 가이드</a>
      <br><a href="https://forms.gle/wBXEg8Byt55so6VY7">중간퀴즈</a>
    </div>
